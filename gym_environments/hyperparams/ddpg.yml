shadow_hand_reach-v0:
    n_timesteps: !!float 4e6
    policy: 'MlpPolicy'
    gamma: 0.95
    memory_limit: 1000000
    noise_type: 'normal'
    noise_std: 0.22
    batch_size: 256
    normalize_observations: False
    normalize_returns: False
    actor_lr: !!float 1e-3
    critic_lr: !!float 1e-3
    #policy_kwargs: "dict(layers=[64, 64])" default

shadow_hand_block-v0:
    n_timesteps: !!float 1e6
    policy: 'MlpPolicy'
    gamma: 0.95
    memory_limit: 1000000
    noise_type: 'normal'
    noise_std: 0.22
    batch_size: 256
    normalize_observations: False
    normalize_returns: False
    policy_kwargs: "dict(layers=[256, 256, 256])"

shadow_hand_reach-v1:
    n_timesteps: !!float 2.5e6
    policy: 'MlpPolicy'
    gamma: 0.95
    memory_limit: 1000000
    noise_type: 'normal'
    noise_std: 0.22
    batch_size: 256
    normalize_observations: False
    normalize_returns: False
    actor_lr: !!float 1e-3
    critic_lr: !!float 1e-3
    policy_kwargs: "dict(layers=[256, 256, 256])"
